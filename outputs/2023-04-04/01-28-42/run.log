[2023-04-04 01:28:42,679][haystack.modeling.utils][INFO] - Using devices: CPU - Number of GPUs: 0
[2023-04-04 01:28:42,681][haystack.pipelines.base][INFO] - It seems that an indexing Pipeline is run, so using the nodes' run method instead of run_batch.
[2023-04-04 01:28:43,048][haystack.nodes.preprocessor.preprocessor][WARNING] - We found one or more sentences whose word count is higher than the split length.
[2023-04-04 01:28:43,077][haystack.nodes.preprocessor.preprocessor][WARNING] - Document b48fb0da693eb4d81b3566d0069868b3 is 10488 characters long after preprocessing, where the maximum length should be 10000. Something might be wrong with the splitting, check the document affected to prevent issues at query time.
[2023-04-04 01:28:43,220][haystack.nodes.preprocessor.preprocessor][WARNING] - Document dd048b8e5bcb7de1be5bd3937f15442f is 14232 characters long after preprocessing, where the maximum length should be 10000. Something might be wrong with the splitting, check the document affected to prevent issues at query time.
[2023-04-04 01:28:43,268][haystack.nodes.preprocessor.preprocessor][WARNING] - Document 4189b42892b3d941c035947d512b69dd is 12059 characters long after preprocessing, where the maximum length should be 10000. Something might be wrong with the splitting, check the document affected to prevent issues at query time.
[2023-04-04 01:28:43,894][haystack.modeling.utils][INFO] - Using devices: CPU - Number of GPUs: 0
[2023-04-04 01:28:43,894][haystack.modeling.utils][INFO] - Using devices: CPU - Number of GPUs: 0
[2023-04-04 01:28:44,138][haystack.modeling.model.language_model][INFO] -  * LOADING MODEL: 'deepset/roberta-base-squad2' (Roberta)
[2023-04-04 01:28:45,681][haystack.modeling.model.language_model][INFO] - Auto-detected model language: english
[2023-04-04 01:28:45,684][haystack.modeling.model.language_model][INFO] - Loaded 'deepset/roberta-base-squad2' (Roberta model) from model hub.
[2023-04-04 01:28:47,416][haystack.modeling.utils][INFO] - Using devices: CPU - Number of GPUs: 0
[2023-04-04 01:29:08,183][haystack.document_stores.memory][WARNING] - InMemoryDocumentStore does not support scale_score for BM25 retrieval. This parameter is ignored.
[2023-04-04 01:29:09,160][root][ERROR] - got unexpected error processing a message: The expanded size of the tensor (584) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 584].  Tensor sizes: [1, 512].
Traceback (most recent call last):
  File "/home/sami/.local/lib/python3.8/site-packages/dbus_next/message_bus.py", line 621, in _on_message
    self._process_message(msg)
  File "/home/sami/.local/lib/python3.8/site-packages/dbus_next/message_bus.py", line 712, in _process_message
    handler(msg, send_reply)
  File "/home/sami/.local/lib/python3.8/site-packages/dbus_next/message_bus.py", line 731, in handler
    result = method.fn(interface, *args)
  File "/home/sami/editAI/qa.py", line 74, in ask
    return self._ask(question)
  File "/home/sami/editAI/qa.py", line 91, in _ask
    outputs = self.model.generate(inputs, max_length = self.answer_length)
  File "/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py", line 27, in decorate_context
    return func(*args, **kwargs)
  File "/home/sami/.local/lib/python3.8/site-packages/transformers/generation/utils.py", line 1406, in generate
    return self.greedy_search(
  File "/home/sami/.local/lib/python3.8/site-packages/transformers/generation/utils.py", line 2201, in greedy_search
    outputs = self(
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/sami/.local/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py", line 1234, in forward
    outputs = self.bert(
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/sami/.local/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py", line 986, in forward
    buffered_token_type_ids_expanded = buffered_token_type_ids.expand(batch_size, seq_length)
RuntimeError: The expanded size of the tensor (584) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [1, 584].  Tensor sizes: [1, 512]

